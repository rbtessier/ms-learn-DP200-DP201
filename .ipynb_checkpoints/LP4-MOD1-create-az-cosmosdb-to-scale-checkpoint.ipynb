{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Azure Cosmos DB database bulit to scale\n",
    "Databases need to scale to meet both the data velocity and volume demands created by global audiences.\n",
    "\n",
    "Db should automatically to account for new products, and have high throughput and low latency to kee pace with customers expectations.\n",
    "## Learning objectives\n",
    "In this module, you will:\n",
    "\n",
    "- Create an Azure Cosmos DB account\n",
    "- Set the initial throughput volume for your database using request units\n",
    "- Choose a partition key\n",
    "- Create a database and container for NoSQL data in Azure Cosmos DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main ideas to remember\n",
    "- Provisioning Throughput for containers and databases - shared across all containers in the db. Need to estimate number of operations you'll have to support at different times.\n",
    "- Request unit (RU) measured per second - must be provisioned in advance. Based on approx cost of single GET request on a 1-KB document using doc ID. GET is cheap, Create, replace or delete is more expensive.\n",
    "- [Find the resquest unit charge in Azure Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/find-request-unit-charge?tabs=dotnetv2)\n",
    "- Request unit considerations\n",
    "  - Item size\n",
    "  - Item indexing\n",
    "  - Item property count\n",
    "  - Indexed properties (limit by policy)\n",
    "  - Data consistency\n",
    "  - Query patterns\n",
    "    - Number of query results\n",
    "    - Number of predicates\n",
    "    - Nature of predicates\n",
    "    - number of user defined functions\n",
    "    - size of the source data\n",
    "    - size of the result set\n",
    "    - Projections\n",
    "  - script usage\n",
    "- When you create and account you can provision a min of 400 RU/s, or a maximum of 250,000 RU/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition strategy\n",
    "ensures that your database can grow to efficiently run queries and transations. Enables horizontal scaling - adding more partitions as needed. A partition key defines this, **can't be changed**, so deciding on this beforehand is hugely important.\n",
    "\n",
    "When additional physical partitions are needed, Cosmos DB automatically creates them by splitting exiting ones. No downtime or performance impact for this.\n",
    "\n",
    "Storage space for data associated with each partition key can't exceed 20 GB< size of one physical partition in Azure Cosmos DB.\n",
    "\n",
    "So if  individual record going ot be larger than 20 GB< think about using composite key (ie instead of UserID, do userID-date - new partition for each day user visited site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices for choosing partition key\n",
    "- Don't be afraid of choosing partition key that has a large number of values. More values = more scalability\n",
    "- For read heavy workload, review top 3 to 5 queries you plan on using. Value most frequently included in WHERE clause is a good candidate for partition key.\n",
    "- For write-heavy workloads, you'll need to understand transactional needs of your workload, because partition key is the scope of multi-document transactions.\n",
    "\n",
    "For each Cosmos DB, specify partition key that satisfies\n",
    "- high cardinatlity, this option allows data to distribute evenly across all physical partitions\n",
    "- Evenly distribute requests. REmember the total number of RU/s is evenly divided across all physical partitions\n",
    "- Evenly distribute storage. Each partition can grow to 20 gb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`note Aug 9 2020`: Exercise gives option to create Cosmos account and db using\n",
    "1. C#\n",
    "2. Java\n",
    "3. Azure CLI\n",
    "\n",
    "Using Azure CLI first time just to save time to try to get as much of DP 200/201 done before tomorrow when I start my training., next time will try C#. NEvermind I actually had made it with the portal first, and using CLI is pretty straightforward, you use the following commands\n",
    "\n",
    "### Cosmos Account\n",
    "\n",
    "`az cosmosdb create \\\n",
    "    --name $NAME \\\n",
    "    --kind GlobalDocumentDB \\\n",
    "    --resource-group learn-193db41a-9465-4eeb-9eea-f5306bf499dd`\n",
    "    \n",
    "### Cosmos SQL DB\n",
    "\n",
    "`az cosmosdb sql database create \\\n",
    "    --account-name $NAME \\\n",
    "    --name \"Products\" \\\n",
    "    --resource-group learn-193db41a-9465-4eeb-9eea-f5306bf499dd`\n",
    "    \n",
    "### Container + partition key\n",
    "\n",
    "`az cosmosdb sql container create \\\n",
    "    --account-name $NAME \\\n",
    "    --database-name \"Products\" \\\n",
    "    --name \"Clothing\" \\\n",
    "    --partition-key-path \"/productId\" \\\n",
    "    --throughput 1000 \\\n",
    "    --resource-group learn-193db41a-9465-4eeb-9eea-f5306bf499dd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
